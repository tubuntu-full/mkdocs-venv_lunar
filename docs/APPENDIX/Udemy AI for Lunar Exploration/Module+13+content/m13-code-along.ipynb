{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":489236,"sourceType":"datasetVersion","datasetId":202982}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# <center> Advanced ML pipeline with segmentation_models and Callbacks\n","    \n","---"],"metadata":{"id":"kD6lbSNVLszk"}},{"cell_type":"markdown","source":["## **The most important thing to improve your model performance is to understand each and every step taken to build the final model.**\n","\n","*In this notebook, you will see how we increase our accuracy from 0.18 in previous module to 0.8 in this module.*\n"],"metadata":{"id":"CxcJ0zARmGOB"}},{"cell_type":"markdown","source":["# Importing libraries"],"metadata":{"id":"pHL8t-2oLszp"}},{"cell_type":"code","source":["from matplotlib import pyplot as plt  # Displaying images\n","from skimage.io import imread         # Read the images\n","import numpy as np                    # Data Handling\n","import datetime                       # Used in Naming\n","import math                           # Math operations\n","import os                             # Directory files\n","\n","# One Hot Encoded Mask and Dataset Building\n","from tensorflow.keras.utils import to_categorical, Sequence\n","import tensorflow as tf\n","import keras"],"metadata":{"id":"3eItJm1hLszr","execution":{"iopub.status.busy":"2024-01-07T12:06:13.354448Z","iopub.execute_input":"2024-01-07T12:06:13.354877Z","iopub.status.idle":"2024-01-07T12:06:13.360726Z","shell.execute_reply.started":"2024-01-07T12:06:13.354848Z","shell.execute_reply":"2024-01-07T12:06:13.359619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the root directory paths for images and masks\n","img_dir = '/kaggle/input/images/render'\n","mask_dir = '/kaggle/input/images/clean'\n","\n","\n","# Sort the files in root directories, Create and Store the complete image and mask paths\n","images = [os.path.join(img_dir, x) for x in sorted(os.listdir(img_dir))]\n","masks = [os.path.join(mask_dir, x) for x in sorted(os.listdir(mask_dir))]\n","\n","\n","# First 8000 images to be used for training\n","X_train = images[:8000]\n","y_train = masks[:8000]\n","\n","# Remaining can be used for validation purpose\n","X_valid = images[8000:-4]\n","y_valid = masks[8000:-4]\n","\n","# Save some for testing purpose (last 4)\n","X_test = images[-4:]\n","y_test = masks[-4:]\n"],"metadata":{"id":"ofv9tYqEkO5V","execution":{"iopub.status.busy":"2024-01-07T12:06:13.383221Z","iopub.execute_input":"2024-01-07T12:06:13.383990Z","iopub.status.idle":"2024-01-07T12:06:13.450428Z","shell.execute_reply.started":"2024-01-07T12:06:13.383956Z","shell.execute_reply":"2024-01-07T12:06:13.449610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Pipeline\n","class LunarDataset(Sequence):\n","\n","    # Constructor - x_set, y_set, batch_size, dims, classes\n","    def __init__(self, x_set, y_set, batch_size, dims, classes):\n","        pass\n","\n","    # Number of Batches --> total length of images / batch size --> Ceil operation\n","    def __len__(self):\n","        pass\n","\n","    # Fetch the data in batches by using iter and next opertions\n","    def __getitem__(self, idx):\n","        # Get start and end indexes to create a batch of batch size\n","        start_index =\n","        end_index =\n","\n","        # Prepare X and y batches\n","        batch_x =\n","        batch_y =\n","\n","        # Empty lists to append preprocessed Images and Masks Array from the for loop\n","        xtr = []\n","        ytr = []\n","\n","        # For every  image and mask in one batch do the following preprocessing\n","        for idx, (filename_x, filename_y) in enumerate(zip(batch_x, batch_y)):\n","\n","            # Image preprocessing\n","\n","            # Mask preprocessing\n","\n","        # Convert list to arrays ensuring the dtype of mask is also float32\n","\n","\n","        # Return the preprocessed batch of images and respective mask as output\n","        return xtr, ytr"],"metadata":{"id":"8iibzosHkO5Y","execution":{"iopub.status.busy":"2024-01-07T12:06:13.451918Z","iopub.execute_input":"2024-01-07T12:06:13.452249Z","iopub.status.idle":"2024-01-07T12:06:13.463748Z","shell.execute_reply.started":"2024-01-07T12:06:13.452211Z","shell.execute_reply":"2024-01-07T12:06:13.462822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Break Down of Mask Preprocessing\n"],"metadata":{"id":"atpOmSqxPdFV"}},{"cell_type":"code","source":["# Consider an example in training data to understand this\n","mask_sample_path = y_train[1]\n","print(mask_sample_path)"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:13.465026Z","iopub.execute_input":"2024-01-07T12:06:13.465334Z","iopub.status.idle":"2024-01-07T12:06:13.482749Z","shell.execute_reply.started":"2024-01-07T12:06:13.465298Z","shell.execute_reply":"2024-01-07T12:06:13.481754Z"},"id":"f7DgeUnKPdFW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the mask as gray scale\n","sample_mask_arr = imread(mask_sample_path, as_gray=True)\n","print(sample_mask_arr.shape)"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:13.485488Z","iopub.execute_input":"2024-01-07T12:06:13.486408Z","iopub.status.idle":"2024-01-07T12:06:13.513094Z","shell.execute_reply.started":"2024-01-07T12:06:13.486365Z","shell.execute_reply":"2024-01-07T12:06:13.512104Z"},"id":"XnOFS5xLPdFY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cropping the mask\n","sample_mask_cropped = sample_mask_arr[:480, :480]\n","print(sample_mask_cropped.shape)"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:13.514166Z","iopub.execute_input":"2024-01-07T12:06:13.514456Z","iopub.status.idle":"2024-01-07T12:06:13.520084Z","shell.execute_reply.started":"2024-01-07T12:06:13.514433Z","shell.execute_reply":"2024-01-07T12:06:13.519076Z"},"id":"y-zXCzZzPdFa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mask with original size and after cropping\n","fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n","\n","plot_data = ((sample_mask_arr, sample_mask_cropped),\n","            (sample_mask_arr.shape, sample_mask_cropped.shape))\n","\n","for (ax, arr, title) in zip(axes,*(plot_data)) :\n","    ax.imshow(arr)\n","    ax.set_title(title)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:13.521561Z","iopub.execute_input":"2024-01-07T12:06:13.522219Z","iopub.status.idle":"2024-01-07T12:06:14.066905Z","shell.execute_reply.started":"2024-01-07T12:06:13.522184Z","shell.execute_reply":"2024-01-07T12:06:14.065968Z"},"id":"oH8v3mOkPdFa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the unique values in cropped_mask\n","np.unique(sample_mask_cropped)"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.070215Z","iopub.execute_input":"2024-01-07T12:06:14.070986Z","iopub.status.idle":"2024-01-07T12:06:14.083596Z","shell.execute_reply.started":"2024-01-07T12:06:14.070936Z","shell.execute_reply":"2024-01-07T12:06:14.082526Z"},"id":"K4ljRz9OPdFb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What happens if you divide them with 0.07?\n","np.unique(sample_mask_cropped)//0.07"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.084885Z","iopub.execute_input":"2024-01-07T12:06:14.085262Z","iopub.status.idle":"2024-01-07T12:06:14.098256Z","shell.execute_reply.started":"2024-01-07T12:06:14.085226Z","shell.execute_reply":"2024-01-07T12:06:14.097323Z"},"id":"oUyUaOovPdFc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We need to convert the values of 3 to 2 and 10 to 3 after floor operation with 0.07\n","adjusted_mask = sample_mask_cropped//0.07\n","adjusted_mask[adjusted_mask == 3.0] = 2.0\n","adjusted_mask[adjusted_mask == 10.0] = 3.0\n","print(np.unique(adjusted_mask))"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.099824Z","iopub.execute_input":"2024-01-07T12:06:14.100456Z","iopub.status.idle":"2024-01-07T12:06:14.116392Z","shell.execute_reply.started":"2024-01-07T12:06:14.100420Z","shell.execute_reply":"2024-01-07T12:06:14.115495Z"},"id":"JZ6ieMSyPdFe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if any changes in the output (the colors are a bit different! as pixel values changed)\n","plt.imshow(adjusted_mask)"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.117650Z","iopub.execute_input":"2024-01-07T12:06:14.118019Z","iopub.status.idle":"2024-01-07T12:06:14.417626Z","shell.execute_reply.started":"2024-01-07T12:06:14.117984Z","shell.execute_reply":"2024-01-07T12:06:14.416571Z"},"id":"CdHV7G9EPdFf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get 4 channel one hot encoded mask\n","final_sample_mask = to_categorical(adjusted_mask,num_classes=4)\n","final_sample_mask"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.419127Z","iopub.execute_input":"2024-01-07T12:06:14.419561Z","iopub.status.idle":"2024-01-07T12:06:14.431873Z","shell.execute_reply.started":"2024-01-07T12:06:14.419518Z","shell.execute_reply":"2024-01-07T12:06:14.430807Z"},"id":"N5CYTFamPdFg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Excercise to get from one hot to integer encoded mask (post processing)"],"metadata":{"id":"la5admV2PdFh"}},{"cell_type":"code","source":["int_encoded_mask = np.argmax(final_sample_mask, axis=-1)\n","int_encoded_mask"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.433328Z","iopub.execute_input":"2024-01-07T12:06:14.433645Z","iopub.status.idle":"2024-01-07T12:06:14.443185Z","shell.execute_reply.started":"2024-01-07T12:06:14.433619Z","shell.execute_reply":"2024-01-07T12:06:14.442207Z"},"id":"qu8Z1soEPdFh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A dummy 4 channel array\n","np.random.seed(42)\n","dum_arr = np.random.rand(3, 3, 4)\n","dum_arr"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.444453Z","iopub.execute_input":"2024-01-07T12:06:14.444755Z","iopub.status.idle":"2024-01-07T12:06:14.452722Z","shell.execute_reply.started":"2024-01-07T12:06:14.444728Z","shell.execute_reply":"2024-01-07T12:06:14.451750Z"},"id":"gCAyyVWpPdFi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First row has max value of 0.95 on index 1, hence, 1 is returned on (0,0)\n","# Similarly, second row has max value of 0.86 on index 3, hence 3 is returned for (0,1)\n","# So on ...\n","np.argmax(dum_arr, axis=-1)"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.453947Z","iopub.execute_input":"2024-01-07T12:06:14.454324Z","iopub.status.idle":"2024-01-07T12:06:14.464516Z","shell.execute_reply.started":"2024-01-07T12:06:14.454287Z","shell.execute_reply":"2024-01-07T12:06:14.463527Z"},"id":"2FvgKg7tPdFi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creating the Dataset"],"metadata":{"id":"CJWULFjCPdFi"}},{"cell_type":"code","source":["# Parameters\n","batch_size = 16\n","dims = (480, 480)\n","num_classes = 4\n","\n","# Dataset Creation\n","train_dataset =\n","valid_dataset ="],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.469493Z","iopub.execute_input":"2024-01-07T12:06:14.470299Z","iopub.status.idle":"2024-01-07T12:06:14.475816Z","shell.execute_reply.started":"2024-01-07T12:06:14.470270Z","shell.execute_reply":"2024-01-07T12:06:14.474778Z"},"id":"GeGFjj3cPdFj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's visualize our masks"],"metadata":{"id":"Kk5QMvOYkO5a"}},{"cell_type":"code","source":["# Taking a sample batch from train_dataset\n","batch = next(iter(train_dataset)) # Batch Size, Height, Width, Channels (Images, Masks)\n","\n","# Check the shape of batch created --> Images and Masks\n","print(batch[0].shape) # 16 images in a batch\n","print(batch[1].shape) # 16 respective masks in a batch"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:14.477942Z","iopub.execute_input":"2024-01-07T12:06:14.478248Z","iopub.status.idle":"2024-01-07T12:06:15.103047Z","shell.execute_reply.started":"2024-01-07T12:06:14.478221Z","shell.execute_reply":"2024-01-07T12:06:15.102121Z"},"id":"Cg_PyEcmPdFj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the mask\n","sample = batch[1][1] # Second in the batch"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:15.104264Z","iopub.execute_input":"2024-01-07T12:06:15.104659Z","iopub.status.idle":"2024-01-07T12:06:15.109650Z","shell.execute_reply.started":"2024-01-07T12:06:15.104624Z","shell.execute_reply":"2024-01-07T12:06:15.108602Z"},"id":"zWsosUamPdFj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating Subplot for better visualization\n","fig, ((a1, a2, a3), (a4, a5, a6)) = plt.subplots(2, 3, figsize = (10, 8))\n","\n","# For different axes and titles\n","for i, (ax,title) in enumerate(zip((a1, a2, a3, a4, a5, a6),\n","                                   ('Original', 'Combined Mask', 'Background', 'Large Rocks', 'Sky', 'Small Rocks'))):\n","    if i == 0:\n","        ax.imshow(batch[0][1])                    # Second Image in the batch (Original)\n","    elif i == 1:\n","        ax.imshow(np.argmax(sample, axis=-1))     # Converts One Hot encoded mask to Integer Encoded Mask (single channel)\n","    else:\n","        ax.imshow(sample[:, :, i-2])              # Channel Wise Output from Mask\n","\n","    # Set Title and turn off the axis\n","    ax.set_title(title, fontsize=15, weight='bold')\n","    ax.axis('off')\n","\n","# Adjust Layout and Display the Subplot\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"sz--yYp2kO5b","execution":{"iopub.status.busy":"2024-01-07T12:06:15.110766Z","iopub.execute_input":"2024-01-07T12:06:15.111111Z","iopub.status.idle":"2024-01-07T12:06:15.926733Z","shell.execute_reply.started":"2024-01-07T12:06:15.111053Z","shell.execute_reply":"2024-01-07T12:06:15.925750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Let's check out some basic steps of transfer learning using a pretrained model (VGG16)\n"],"metadata":{"id":"lZ3xM6nTZUNX"}},{"cell_type":"markdown","source":["## segmentation_models"],"metadata":{"id":"bAqM5bf_s3QO"}},{"cell_type":"markdown","source":["\n","**segmentation_models** is a python library with Neural Networks for Image Segmentation based on Keras and TensorFlow.\n","\n","The main features of this library are:\n","\n","* High level API (just two lines of code to create model for segmentation)\n","* 4 models architectures for binary and multi-class image segmentation (including legendary Unet)\n","* 25 available backbones for each architecture\n","* All backbones have pre-trained weights for faster and better convergence\n","* Helpful segmentation losses (Jaccard, Dice, Focal) and metrics (IoU, F-score)"],"metadata":{"id":"khcnnP4asNE8"}},{"cell_type":"code","source":["# run this command to directly install the library in our notebook\n","\n","!pip install segmentation_models"],"metadata":{"id":"TQ481azQsf2A","execution":{"iopub.status.busy":"2024-01-07T12:06:15.935643Z","iopub.execute_input":"2024-01-07T12:06:15.935924Z","iopub.status.idle":"2024-01-07T12:06:28.412968Z","shell.execute_reply.started":"2024-01-07T12:06:15.935900Z","shell.execute_reply":"2024-01-07T12:06:28.411754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n","* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')"],"metadata":{"id":"apuK6SQMsbhs"}},{"cell_type":"code","source":["# By default it tries to import keras, if it is not installed, it will try to start with tensorflow.keras framework\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\" # Set the environment variable SM_FRAMEWORK to \"tf.keras\"\n","import segmentation_models as sm        # It will import without any errors if env variable is set properly\n","sm.set_framework('tf.keras')            # Use segmentation_models library and set the framework to TensorFlow's Keras"],"metadata":{"id":"ckhpfcSNsXXG","execution":{"iopub.status.busy":"2024-01-07T12:06:28.414637Z","iopub.execute_input":"2024-01-07T12:06:28.415003Z","iopub.status.idle":"2024-01-07T12:06:28.420986Z","shell.execute_reply.started":"2024-01-07T12:06:28.414951Z","shell.execute_reply":"2024-01-07T12:06:28.419868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the last axis of the tensor as channel axis\n","tf.keras.backend.set_image_data_format('channels_last')\n","# Explicitly setting this is not always necessary, as 'channels_last' is the default setting"],"metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:06:28.422305Z","iopub.execute_input":"2024-01-07T12:06:28.423871Z","iopub.status.idle":"2024-01-07T12:06:28.433531Z","shell.execute_reply.started":"2024-01-07T12:06:28.423843Z","shell.execute_reply":"2024-01-07T12:06:28.432673Z"},"id":"zqJgmL05PdFn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Building our UNet model with segmentation_models"],"metadata":{"id":"Fdtf71zxkO5i"}},{"cell_type":"code","source":["# Parameters for UNET using Segmentation Models\n","BACKBONE =\n","input_shape =\n","n_classes =\n","activation =\n","\n","\n","# Even though backbone doesn't have encoder-decoder structure, it is still able to build it thanks to sm library\n","model = sm.Unet()\n","#                 encoder_weights = 'imagenet',\n","#                 encoder_freeze = True)\n","\n","# Check all the different parameters of UNET, try with them\n","# Uncomment the above two lines of UNET for transfer learning\n","\n","# Check the model summary\n"],"metadata":{"id":"q9UGUpklLsz1","execution":{"iopub.status.busy":"2024-01-07T12:06:28.434718Z","iopub.execute_input":"2024-01-07T12:06:28.436588Z","iopub.status.idle":"2024-01-07T12:06:29.294356Z","shell.execute_reply.started":"2024-01-07T12:06:28.436562Z","shell.execute_reply":"2024-01-07T12:06:29.293356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Compile model"],"metadata":{"id":"jFpUjTLxLsz2"}},{"cell_type":"code","source":["\"\"\" Hyperparameters \"\"\"\n","lr = 1e-4\n","batch_size = 16\n","epochs = 5\n","\n","# metrics for result validation\n","metrics = [sm.metrics.IOUScore(threshold=0.5)]\n","\n","# compiling the model --> Try changing the loss function to jacard_loss from sm library and see changes!\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = tf.keras.optimizers.Adam(lr),\n","              metrics = metrics)\n","\n","# Steps per epoch (training in batches)\n","train_steps = len(X_train)//batch_size\n","valid_steps = len(X_valid)//batch_size\n","\n","\n","\"\"\" Callbacks \"\"\"\n","callbacks = [\n","        tf.keras.callbacks.ReduceLROnPlateau(\n","        ),\n","\n","        tf.keras.callbacks.EarlyStopping(\n","        )\n","    ]"],"metadata":{"id":"BAwylsJgLsz3","execution":{"iopub.status.busy":"2024-01-07T12:06:29.295731Z","iopub.execute_input":"2024-01-07T12:06:29.296028Z","iopub.status.idle":"2024-01-07T12:06:29.315688Z","shell.execute_reply.started":"2024-01-07T12:06:29.296001Z","shell.execute_reply":"2024-01-07T12:06:29.314614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","model is compiled with **loss**=\"categorical_crossentropy\",  **optimizer**=Adam, **metrics**=iou_score\n","\n","**Callbacks** is a tool to customize the behavior of a Keras model during training, evaluation, or inference.\n","\n","**ReduceLROnPlateau:** Reduce learning rate when a metric has stopped improving.\n","\n","**EarlyStopping:** Stop training when a monitored metric has stopped improving."],"metadata":{"id":"UhikbwebLsz3"}},{"cell_type":"markdown","source":["## Train model"],"metadata":{"id":"UPho7ynJLsz4"}},{"cell_type":"code","source":["# Fitting the model\n","model_history = model.fit(train_dataset,\n","        validation_data=valid_dataset,\n","        epochs=epochs,\n","        callbacks=callbacks\n","    )"],"metadata":{"id":"eK6nMaYkLsz4","execution":{"iopub.status.busy":"2024-01-07T12:06:29.316888Z","iopub.execute_input":"2024-01-07T12:06:29.317197Z","iopub.status.idle":"2024-01-07T13:13:44.864225Z","shell.execute_reply.started":"2024-01-07T12:06:29.317170Z","shell.execute_reply":"2024-01-07T13:13:44.863228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict from model"],"metadata":{"id":"IobGiGA6Lsz4"}},{"cell_type":"code","source":["# function to predict result\n","def predict_image(img_path, mask_path, model):\n","    H =\n","    W =\n","    num_classes =\n","\n","    img =\n","    img =\n","    img =\n","    img =\n","\n","    ## Read mask\n","    mask =\n","    mask =\n","\n","    ## Prediction\n","    pred_mask =\n","    pred_mask =\n","    pred_mask =\n","\n","\n","    # calculating IOU score\n","    inter =\n","    union =\n","\n","    iou =\n","\n","    return img, mask, pred_mask, iou"],"metadata":{"id":"W-1_LmkTLsz5","execution":{"iopub.status.busy":"2024-01-07T13:13:44.865796Z","iopub.execute_input":"2024-01-07T13:13:44.866179Z","iopub.status.idle":"2024-01-07T13:13:44.874661Z","shell.execute_reply.started":"2024-01-07T13:13:44.866143Z","shell.execute_reply":"2024-01-07T13:13:44.873666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_path = X_test[0]\n","mask_path = y_test[0]\n","\n","img, mask, pred_mask, iou = predict_image(img_path, mask_path, model)\n","\n","fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (15, 10))\n","\n","ax1.set_title(\"Input Image\")\n","ax1.imshow(img)\n","\n","ax2.set_title(\"True Mask\")\n","ax2.imshow(mask)\n","\n","ax3.set_title(\"Predicted mask with IOU score %.2f\"%(iou))\n","ax3.imshow(pred_mask)\n","\n","plt.show()"],"metadata":{"id":"314r8EbTLsz6","execution":{"iopub.status.busy":"2024-01-07T13:17:44.819381Z","iopub.execute_input":"2024-01-07T13:17:44.820062Z","iopub.status.idle":"2024-01-07T13:17:45.667827Z","shell.execute_reply.started":"2024-01-07T13:17:44.820029Z","shell.execute_reply":"2024-01-07T13:17:45.666898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model, save_model"],"metadata":{"id":"7VuTWtICEO0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the Model\n","save_model(model, 'LunarModel.h5')"],"metadata":{"id":"7QFTcfRLEP59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the Model\n","loaded_model = load_model('/kaggle/working/LunarModel.h5')"],"metadata":{"id":"NsZS_2d3ERQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, _, _, iou_score = predict_image(img_path, mask_path, loaded_model)\n","print(iou_score)"],"metadata":{"id":"IVqNfhlfETE3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### You can see we have reached a satisfactory result for our project."],"metadata":{"id":"qgfn0B86kO5m"}}]}